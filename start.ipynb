{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dcor/niskhizov/Prosody2Vec\n"
     ]
    }
   ],
   "source": [
    "cd Prosody2Vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "from funasr import AutoModel\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model=\"iic/emotion2vec_base\"\n",
    "# model=\"iic/emotion2vec_base_finetuned\"\n",
    "# model=\"iic/emotion2vec_plus_seed\"\n",
    "# model=\"iic/emotion2vec_plus_base\"\n",
    "model_id = \"iic/emotion2vec_plus_large\"\n",
    "\n",
    "sed_model = AutoModel(\n",
    "    model=model_id,\n",
    "    hub=\"ms\",  # \"ms\" or \"modelscope\" for China mainland users; \"hf\" or \"huggingface\" for other overseas users\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "\n",
    "# Load the content encoder (either hubert_soft or hubert_discrete)\n",
    "hubert = torch.hub.load(\"bshall/hubert:main\", \"hubert_soft\", trust_repo=True).cuda()\n",
    "\n",
    "# Load the acoustic model (either hubert_soft or hubert_discrete)\n",
    "acoustic = torch.hub.load(\"bshall/acoustic-model:main\", \"hubert_soft\", trust_repo=True).cuda()\n",
    "\n",
    "# Load the vocoder (either hifigan_hubert_soft or hifigan_hubert_discrete)\n",
    "hifigan = torch.hub.load(\"bshall/hifigan:main\", \"hifigan_hubert_soft\", trust_repo=True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "class LogMelSpectrogram(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.melspctrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=1024,\n",
    "            win_length=1024,\n",
    "            hop_length=160,\n",
    "            center=False,\n",
    "            power=1.0,\n",
    "            norm=\"slaney\",\n",
    "            onesided=True,\n",
    "            n_mels=128,\n",
    "            mel_scale=\"slaney\",\n",
    "        )\n",
    "\n",
    "    def forward(self, wav):\n",
    "        padding = (1024 - 160) // 2\n",
    "        wav = F.pad(wav, (padding, padding), \"reflect\")\n",
    "        mel = self.melspctrogram(wav)\n",
    "        logmel = torch.log(torch.clamp(mel, min=1e-5))\n",
    "        return logmel\n",
    "    \n",
    "logmel = LogMelSpectrogram().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spk_ecapa_tdnn = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = './Emotion Speech Dataset/'\n",
    "data_dir = '/home/dcor/niskhizov/Prosody2Vec/IEMOCAP_full_release/'\n",
    "# scan recursively for all .wav files in the data_dir\n",
    "wav_files = glob.glob(data_dir + '/**/*.wav', recursive=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = [x for x in wav_files if 'sentences' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(wav_files)\n",
    "wav_file = wav_files[0]\n",
    "\n",
    "wav, sr = torchaudio.load(wav_file)\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(wav.squeeze().numpy(), rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir iemocap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vecs(units, emo_vec, spk_vec, logmel, out_file):\n",
    "    with open(out_file, 'wb') as f:\n",
    "        pickle.dump({'units': units, 'emo_vec': emo_vec, 'spk_vec': spk_vec, 'logmel': logmel}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hubert embeddings, emotion embeddings, and speaker embeddings\n",
    "\n",
    "for wav_path in tqdm.tqdm(wav_files):\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    with torch.inference_mode():\n",
    "        # Extract speech units\n",
    "        units = hubert.units(wav.unsqueeze(0).cuda())\n",
    "\n",
    "        emo_vec = sed_model.generate(wav, granularity=\"utterance\", extract_embedding=True, disable_pbar =True)[0]['feats']\n",
    "\n",
    "        spk_vec = spk_ecapa_tdnn.encode_batch(wav.cuda())\n",
    "\n",
    "        melspec = logmel(wav.cuda())\n",
    "    \n",
    "    out_file = f\"iemocap_embeddings/{wav_path.split('/')[-1].replace('.wav', '.pkl')}\"\n",
    "    save_vecs(units[0].cpu(), emo_vec, spk_vec[0][0].cpu(), melspec[0].cpu(), out_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
